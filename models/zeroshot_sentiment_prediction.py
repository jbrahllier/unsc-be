#!/usr/bin/env python
"""
zeroshot_sentiment_prediction.py

Add zero-shot sentiment predictions (positive/negative/neutral) for every
actor predicted by the actor classification script.

Use Example:
-------
python append_sentiment.py \
    --predictions_csv predictions.csv \
    --output_csv predictions_with_sentiment.csv
"""
import argparse
import ast
import json
import os
from typing import List, Dict

import numpy as np
import pandas as pd
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from tqdm.auto import tqdm

ZS_MODEL_NAME = "MoritzLaurer/ModernBERT-large-zeroshot-v2.0"
SENT_TEMPLATES: Dict[str, List[str]] = {
    "positive": [
        "The UNSC’s overall stance towards {actor} is positive.",
        "Comments about {actor} are favorable.",
        "The tone regarding {actor} is supportive."
    ],
    "negative": [
        "The UNSC’s overall stance towards {actor} is negative.",
        "Comments about {actor} are unfavorable.",
        "The tone regarding {actor} is unsupportive."
    ],
    "neutral": [
        "The UNSC’s overall stance towards {actor} is neutral.",
        "Sentiment expressed about {actor} is moderate.",
        "The tone regarding {actor} is impartial."
    ],
}
ENTAIL_IDX = 0               # ModernBERT puts the “entailment” logit at index-0
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
BATCH_SIZE = 8               # keep small if you’re on CPU / low-VRAM GPU

def load_zero_shot_model(model_name: str = ZS_MODEL_NAME):
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)
    model = AutoModelForSequenceClassification.from_pretrained(model_name)
    return tokenizer, model.to(DEVICE).eval()

def sentiment_for_pair(premise: str, actor: str, tok, mdl, max_length: int,) -> str:
    """
    Evaluate (premise, hypothesis) pairs across every template and sentiment,
    then return the sentiment with the highest average entailment log-prob.
    """
    scores = {s: [] for s in SENT_TEMPLATES}
    with torch.no_grad():
        for sentiment, templates in SENT_TEMPLATES.items():
            for template in templates:
                hypothesis = template.format(actor=actor)
                enc = tok(
                    premise,
                    hypothesis,
                    truncation="only_first",
                    padding="longest",
                    max_length=max_length,
                    return_tensors="pt",
                ).to(DEVICE)

                logits = mdl(**enc).logits.squeeze(0)
                scores[sentiment].append(logits[ENTAIL_IDX].item())

    # average over templates for robustness
    avg_scores = {s: np.mean(v) for s, v in scores.items()}
    return max(avg_scores, key=avg_scores.get)   # str: pos / neg / neutral

def append_sentiments(df: pd.DataFrame, tok, mdl, max_len: int,) -> pd.DataFrame:
    """
    Loop row-wise, produce a parallel list of sentiments for every actor list.
    """
    sentiments_all: List[List[str]] = []

    for premise, actor_str in tqdm(
        zip(df["clause"], df["predicted_actors"]),
        total=len(df),
        desc="Zero-shot sentiment",
    ):
        # tolerate both list & stringified-list inputs
        if isinstance(actor_str, str):
            actors = ast.literal_eval(actor_str)
        else:
            actors = actor_str

        clause_sents: List[str] = [
            sentiment_for_pair(premise, a, tok, mdl, max_len) for a in actors
        ]
        sentiments_all.append(clause_sents)

    df["predicted_sentiments"] = sentiments_all
    return df


def main(args):
    # load actor predictions 
    if not os.path.exists(args.predictions_csv):
        raise FileNotFoundError(f"{args.predictions_csv} does not exist.")
    df = pd.read_csv(args.predictions_csv)
    if "clause" not in df.columns or "predicted_actors" not in df.columns:
        raise ValueError(
            "Input CSV must contain 'clause' and 'predicted_actors' columns."
        )

    # load zero-shot model 
    tok, mdl = load_zero_shot_model(args.model_name)
    max_len = tok.model_max_length

    # sentiment inference 
    df = append_sentiments(df, tok, mdl, max_len)

    # save 
    os.makedirs(os.path.dirname(args.output_csv) or ".", exist_ok=True)
    df.to_csv(args.output_csv, index=False)
    print(f"Sentiment-enhanced predictions saved at {args.output_csv}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Append zero-shot sentiment predictions to actor output CSV."
    )
    parser.add_argument(
        "--predictions_csv",
        required=True,
        help="CSV generated by the actor classification script (contains predicted_actors).",
    )
    parser.add_argument(
        "--output_csv",
        default="predictions_with_sentiments.csv",
        help="Destination CSV path.",
    )
    parser.add_argument(
        "--model_name",
        default=ZS_MODEL_NAME,
        help="HF model to use for zero-shot sentiment NLI.",
    )
    args = parser.parse_args()

    main(args)
